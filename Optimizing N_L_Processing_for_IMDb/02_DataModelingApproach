The data consisted of 50,000 IMDb movie reviews, each paired with a sentiment label. The raw input was unstructured text, while the target variable was categorical sentiment. Labels were converted into a numerical format to support supervised learning, and the dataset was split into training and test partitions to support out‑of‑sample evaluation. The primary modeling approach combined text vectorization with a feedforward neural network. Text was transformed into numeric representations using a multi‑hot encoding strategy over a limited vocabulary. This encoding captured the presence or absence of words within each review without considering word order. The resulting vectors served as inputs to a neural network with a hidden layer and a softmax output layer for binary classification. This approach was appropriate because it establishes a strong baseline for text classification while remaining computationally efficient and interpretable. The model leverages distributional properties of language—specifically, that word usage patterns correlate with sentiment—without requiring complex sequence modeling. The neural network provides non‑linear decision boundaries that improve upon linear classifiers while remaining relatively simple to train and tune.
