Model performance was evaluated using classification accuracy and ROC‑AUC, both of which provide complementary perspectives on predictive quality. Accuracy measured the proportion of correctly classified cases, while ROC‑AUC assessed the model’s ability to discriminate between positive and negative outcomes across classification thresholds. ROC‑AUC was particularly important in this context because it is insensitive to class imbalance and provides insight into ranking performance rather than relying on a single cutoff. This is critical in medical prediction problems, where the relative cost of false negatives and false positives may differ. The results demonstrated that the model achieved solid predictive performance, indicating that the ensemble successfully captured meaningful nonlinear relationships in the data. However, there are limitations. The dataset is relatively small, which increases the risk of overfitting even with regularization and early stopping. Additionally, while feature importance provides directional insight, it does not fully explain causal relationships, and the model remains less interpretable than simpler approaches such as logistic regression. The XGBoost feature importance plot further demonstrated that variables such as glucose level and BMI contributed most strongly to the model’s predictive power, reinforcing that the ensemble prioritized clinically relevant features when making classification decisions.
