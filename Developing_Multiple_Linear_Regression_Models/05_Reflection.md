This assignment reinforced the importance of disciplined model building rather than relying solely on automated or maximal approaches. One key lesson was that adding more predictors does not guarantee better predictive performance, especially when evaluated on future data. Statistical significance and out‑of‑sample validation are essential tools for guarding against overfitting. If this analysis were repeated, additional steps such as examining residual plots, testing interaction terms, or comparing against regularized regression methods could provide further insight. In real‑world scenarios, this approach directly applies to business and healthcare analytics, where model interpretability, robustness, and predictive reliability are often more valuable than marginal gains in sample accuracy.
