The code begins by importing TensorFlow and Keras for model construction and training, NumPy for numerical operations, and Matplotlib for visualization. A fixed random seed is set to ensure reproducibility across training runs. The Fashion‑MNIST dataset is loaded directly through Keras utilities, providing both image tensors and corresponding labels. Exploratory steps include inspecting dataset dimensions, mapping label indices to category names, and visualizing a sample of images to understand image quality and class variation. Prior to training, all pixel values are normalized by dividing by 255, scaling inputs to the range from 0 to 1. This normalization improves numerical stability during optimization. For the baseline model, the code defines an input layer that accepts 28×28 images, flattens the input into a one‑dimensional vector, and passes it through a dense hidden layer with ReLU activation. The output layer applies a softmax function to generate probabilities for each of the ten classes. The model is compiled with Adam optimization and accuracy as the evaluation metric, then trained for ten epochs using a validation split drawn from the training data. For the convolutional neural network, the code adds a channel dimension to the input data and defines two convolutional blocks with convolution and pooling layers. After flattening the resulting feature maps, the model outputs class probabilities using a softmax layer. The CNN is trained using the same optimization settings as the baseline model, allowing for a direct comparison of results. Model summaries are used to inspect architecture depth and parameter counts, and final performance is evaluated using the held‑out test set.
