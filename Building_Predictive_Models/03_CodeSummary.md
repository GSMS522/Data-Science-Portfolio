The code implemented a full end‑to‑end classification workflow. It began by loading the loan dataset and isolating relevant variables for analysis. Exploratory steps were used to separate defaulted and non‑defaulted loans and compare summary statistics, helping validate that meaningful differences existed between the two groups. The dataset was then split into training and test sets, ensuring that model evaluation was performed on data not used during model fitting. A logistic regression model was defined using a formula‑based interface, where the default indicator served as the dependent variable and all borrower attributes were treated as predictors. Once trained, the model generated predicted probabilities of default for the test data. These probabilities were converted into binary predictions using a specified threshold, enabling direct comparison with actual outcomes. Model performance was assessed using a confusion matrix and accuracy metric, which quantified how often the model correctly classified defaults and non‑defaults. Key libraries used included: pandas and NumPy for data manipulation, statsmodels for logistic regression estimation, scikit‑learn for data splitting and evaluation metrics, matplotlib and seaborn for visualization. Overall, the code operationalized the statistical concepts of classification, probability estimation, and out‑of‑sample evaluation.
